## General
experiment_name: "MeanScale_5_lambda200-3200_direct_200"
results_path : "./results"

# Model
model:
  entropy_model: 
    type: "MeanScaleHyperprior" 
    C_in: 128
    C_bottleneck: 128
    num_bottlenecks: 5
  g_a: 
    C_in: 3
    N1: 64
    N2: 128
    N3: 128
  g_s:
    C_out: 3
    N1: 64
    N2: 128
    N3: 128

## Data
data_path: "./data/datasets/full_128"
min_points_train: 100
min_points_test: 0
transforms:
  train:
    1_Rotate:
      key: "RandomRotate"
      block_size: 128
    2_Project:
      key: "ProjectTexture"
      block_size: 128
      dataset_dir: ./data/datasets
    3_Rotate:
      key: "RandomRotate"
      block_size: 128

## Training
device: "0"
epochs: 200
batch_size: 8
virtual_batches: false
model_learning_rate: 0.0001
bottleneck_learning_rate: 0.01
optimizer: "Adam"
scheduler_step_size: 30
scheduler_gamma: 0.5
clip_grad_norm: 1.0

## Loss:
loss:
  ColorLoss:
    type: "StackedColorLoss"
    weight:
      - 200
      - 400
      - 800
      - 1600
      - 3200
    loss: "L2"
  bpp-y:
    type: "StackedBPPLoss"
    key: "y"
    weight: 1.0
  bpp-z:
    type: "StackedBPPLoss"
    key: "z"
    weight: 1.0